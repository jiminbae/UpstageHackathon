import pandas as pd
import json
import argparse

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Analyze Crawled Complaint Data")
    parser.add_argument("--district_name", type=str, default="dalseo", 
                        choices=["dalseo", "suseong", "nam", "dong", "jung", "seo", "buk", "dalseong"],
                        help="Name of the district")
    args = parser.parse_args()

#file_path = f'raw_data/crawled_posts_{args.district_name}.json'
file_path = f'db/input_set_{args.district_name}.json'

# JSON íŒŒì¼ ì½ê¸°
with open(file_path, 'r', encoding='utf-8') as f:
    data = json.load(f)

# DataFrame ìƒì„±
df = pd.DataFrame(data)

# ë‹µë³€ ì •ë³´ë¥¼ ë³„ë„ ì»¬ëŸ¼ìœ¼ë¡œ ë¶„ë¦¬
df['answer_dept'] = df['answer'].apply(lambda x: x.get('dept') if isinstance(x, dict) else None)
df['answer_date'] = df['answer'].apply(lambda x: x.get('date') if isinstance(x, dict) else None)
df['answer_receipt_no'] = df['answer'].apply(lambda x: x.get('receipt_no') if isinstance(x, dict) else None)
df['answer_author'] = df['answer'].apply(lambda x: x.get('author') if isinstance(x, dict) else None)
df['answer_phone'] = df['answer'].apply(lambda x: x.get('phone') if isinstance(x, dict) else None)
df['answer_content'] = df['answer'].apply(lambda x: x.get('content') if isinstance(x, dict) else None)

# ì›ë³¸ answer ì»¬ëŸ¼ ì œê±°
df = df.drop('answer', axis=1)

# ë‚ ì§œ ì»¬ëŸ¼ì„ datetimeìœ¼ë¡œ ë³€í™˜
df['created_date'] = pd.to_datetime(df['created_date'], errors='coerce')
df['answer_date'] = pd.to_datetime(df['answer_date'], errors='coerce')

# ë‚ ì§œ ì°¨ì´ ê³„ì‚° (ì¼ ë‹¨ìœ„)
df['response_days'] = (df['answer_date'] - df['created_date']).dt.days

# ì‹œê°„ ì°¨ì´ ê³„ì‚° (ì‹œê°„ ë‹¨ìœ„, ì†Œìˆ˜ì  í¬í•¨)
df['response_hours'] = (df['answer_date'] - df['created_date']).dt.total_seconds() / 3600

# í™•ì¸
print(df.info())
print("\n=== ì‘ë‹µ ì‹œê°„ í†µê³„ ===")
print(df[['id', 'title', 'created_date', 'answer_date', 'response_days', 'response_hours']].head(10))

print("\n=== ì‘ë‹µ ì†Œìš”ì¼ ê¸°ìˆ í†µê³„ ===")
print(df['response_days'].describe())

print("\n=== ë¶€ì„œë³„ í‰ê·  ì‘ë‹µ ì†Œìš”ì¼ ===")
dept_response = df.groupby('answer_dept')['response_days'].agg(['mean', 'median', 'min', 'max', 'count'])
print(dept_response.sort_values('mean', ascending=False))

# ì‘ë‹µì´ ë¹ ë¥¸/ëŠë¦° ë¯¼ì› ì°¾ê¸°
print("\n=== ê°€ì¥ ë¹ ë¥¸ ì‘ë‹µ TOP 5 ===")
print(df.nsmallest(5, 'response_days')[['title', 'answer_dept', 'response_days']])

print("\n=== ê°€ì¥ ëŠë¦° ì‘ë‹µ TOP 5 ===")
print(df.nlargest(5, 'response_days')[['title', 'answer_dept', 'response_days']])

# ì‘ë‹µ ì‹œê°„ ë¶„í¬
print("\n=== ì‘ë‹µ ì‹œê°„ êµ¬ê°„ë³„ ë¶„í¬ ===")
bins = [0, 1, 3, 7, 14, 30, float('inf')]
labels = ['ë‹¹ì¼', '1-3ì¼', '3-7ì¼', '1-2ì£¼', '2-4ì£¼', '4ì£¼ ì´ìƒ']
df['response_category'] = pd.cut(df['response_days'], bins=bins, labels=labels)
print(df['response_category'].value_counts().sort_index())

# ======= ë™ëª…ì´ì¸ í™•ì¸ (ì´ë¦„ë§Œìœ¼ë¡œ íŒë‹¨, 'â—‹â—‹' í¬í•¨ ì´ë¦„ ì œì™¸) =======
print("\n" + "="*60)
print("=== ë™ëª…ì´ì¸ ë¶„ì„ (ê°™ì€ ì´ë¦„ = ë™ëª…ì´ì¸) ===")
print("="*60)

# ë¸”ë¼ì¸ë“œ ì²˜ë¦¬ëœ ì´ë¦„ í™•ì¸ ('â—‹'ì´ í¬í•¨ëœ ì´ë¦„)
blind_mask = df['author'].str.contains('â—‹', na=False)
blind_count = blind_mask.sum()

if blind_count > 0:
    print(f"âš ï¸  ë¸”ë¼ì¸ë“œ ì²˜ë¦¬ëœ ë¯¼ì›: {blind_count}ê±´ (ë¶„ì„ì—ì„œ ì œì™¸)")
    # ë¸”ë¼ì¸ë“œ ì²˜ë¦¬ëœ ì´ë¦„ ì¢…ë¥˜ í™•ì¸
    blind_names = df[blind_mask]['author'].unique()
    print(f"   ë¸”ë¼ì¸ë“œ ì´ë¦„ ì¢…ë¥˜: {', '.join(blind_names[:10])}" + 
          (f" ì™¸ {len(blind_names)-10}ê°œ" if len(blind_names) > 10 else ""))

# 1. ë¸”ë¼ì¸ë“œ ì²˜ë¦¬('â—‹' í¬í•¨)ë¥¼ ì œì™¸í•˜ê³  ê°™ì€ ì´ë¦„ì„ ê°€ì§„ ì‚¬ëŒë“¤ ì°¾ê¸°
df_filtered = df[~blind_mask]
name_counts = df_filtered['author'].value_counts()
duplicated_names = name_counts[name_counts > 1]

if len(duplicated_names) > 0:
    print(f"\nğŸ“Š ë™ëª…ì´ì¸ (ì¤‘ë³µëœ ì´ë¦„): {len(duplicated_names)}ê°œ")
    print(f"ì´ ë™ëª…ì´ì¸ ë¯¼ì› ê±´ìˆ˜: {duplicated_names.sum()}ê±´\n")
    
    # ê±´ìˆ˜ê°€ ë§ì€ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ì¶œë ¥
    print("=== ì¤‘ë³µ ê±´ìˆ˜ ìˆœìœ„ ===")
    for idx, (name, count) in enumerate(duplicated_names.items(), 1):
        print(f"{idx}. {name}: {count}ê±´")
    
    # 2. ë™ëª…ì´ì¸ ìƒì„¸ ë¶„ì„
    print("\n" + "="*60)
    print("=== ë™ëª…ì´ì¸ ìƒì„¸ ì •ë³´ ===")
    print("="*60)
    for name, count in duplicated_names.items():
        print(f"\nğŸ‘¤ ì´ë¦„: {name} ({count}ê±´)")
        same_name_df = df_filtered[df_filtered['author'] == name][['id', 'created_date', 'title', 'answer_dept']]
        same_name_df = same_name_df.sort_values('created_date', ascending=False)
        
        # ì¶œë ¥ í˜•ì‹ ê°œì„ 
        for idx, row in same_name_df.iterrows():
            date_str = row['created_date'].strftime('%Y-%m-%d') if pd.notna(row['created_date']) else 'N/A'
            dept_str = row['answer_dept'] if pd.notna(row['answer_dept']) else 'ë¯¸ë‹µë³€'
            print(f"  [{date_str}] {row['title'][:60]}")
            print(f"    ë‹´ë‹¹: {dept_str}")
        
        # í†µê³„ ì •ë³´
        answered = same_name_df['answer_dept'].notna().sum()
        print(f"\n  ğŸ“Š í†µê³„: ì´ {count}ê±´ (ë‹µë³€ {answered}ê±´, ë¯¸ë‹µë³€ {count-answered}ê±´)")
        
        if answered > 0:
            # ë‹´ë‹¹ ë¶€ì„œ ë¶„í¬
            dept_dist = same_name_df['answer_dept'].value_counts()
            print(f"  ğŸ“ ë‹´ë‹¹ ë¶€ì„œ ë¶„í¬:")
            for dept, dept_count in dept_dist.items():
                print(f"    - {dept}: {dept_count}ê±´")
        
        print("-" * 60)
    
    # 3. ë™ëª…ì´ì¸ ë¯¼ì› íŒ¨í„´ ë¶„ì„
    print("\n=== ë™ëª…ì´ì¸ ë¯¼ì› íŒ¨í„´ ë¶„ì„ ===")
    
    # 3-1. ê°™ì€ ë¶€ì„œì— ì—¬ëŸ¬ ë²ˆ ë¯¼ì› ì œì¶œí•œ ê²½ìš°
    print("\n[ê°™ì€ ë¶€ì„œì— ì—¬ëŸ¬ ë²ˆ ë¯¼ì›í•œ ë™ëª…ì´ì¸]")
    has_repeated = False
    for name in duplicated_names.index:
        name_df = df_filtered[df_filtered['author'] == name]
        dept_counts = name_df['answer_dept'].value_counts()
        repeated_depts = dept_counts[dept_counts > 1]
        
        if len(repeated_depts) > 0:
            has_repeated = True
            print(f"  - {name}:")
            for dept, count in repeated_depts.items():
                print(f"    {dept}: {count}ê±´")
    
    if not has_repeated:
        print("  ì—†ìŒ")
    
    # 3-2. ë¯¼ì› ì œì¶œ ê¸°ê°„ ë¶„ì„
    print("\n[ë¯¼ì› ì œì¶œ ê¸°ê°„]")
    for name in duplicated_names.index:
        name_df = df_filtered[df_filtered['author'] == name].sort_values('created_date')
        if len(name_df) > 0 and name_df['created_date'].notna().any():
            first_date = name_df['created_date'].min()
            last_date = name_df['created_date'].max()
            period = (last_date - first_date).days
            
            print(f"  - {name}: {first_date.strftime('%Y-%m-%d')} ~ {last_date.strftime('%Y-%m-%d')} ({period}ì¼)")

else:
    print("\nâœ“ ë™ëª…ì´ì¸ ì—†ìŒ (ë¸”ë¼ì¸ë“œ ì œì™¸ ì‹œ ëª¨ë“  ì´ë¦„ì´ ê³ ìœ í•¨)")

# 4. ì „ì²´ í†µê³„ ìš”ì•½
print("\n" + "="*60)
print("=== ë¯¼ì›ì¸ í†µê³„ ìš”ì•½ ===")
print("="*60)
print(f"ì´ ë¯¼ì› ê±´ìˆ˜: {len(df)}ê±´")
print(f"ë¸”ë¼ì¸ë“œ ì²˜ë¦¬: {blind_count}ê±´")
print(f"ì‹¤ëª… ë¯¼ì›: {len(df_filtered)}ê±´")
print(f"ê³ ìœ  ì´ë¦„ ìˆ˜ (ë¸”ë¼ì¸ë“œ ì œì™¸): {df_filtered['author'].nunique()}ëª…")
print(f"ë™ëª…ì´ì¸ ì´ë¦„ ìˆ˜: {len(duplicated_names)}ê°œ")
print(f"1ì¸ 1ê±´ ë¯¼ì›ì¸: {len(name_counts[name_counts == 1])}ëª…")
print(f"1ì¸ ë‹¤ê±´ ë¯¼ì›ì¸: {len(duplicated_names)}ëª…")

if len(duplicated_names) > 0:
    print(f"\n[1ì¸ë‹¹ í‰ê·  ë¯¼ì› ê±´ìˆ˜ (ë¸”ë¼ì¸ë“œ ì œì™¸)]")
    print(f"  - ì „ì²´ í‰ê· : {len(df_filtered) / df_filtered['author'].nunique():.2f}ê±´")
    print(f"  - ë™ëª…ì´ì¸ í‰ê· : {duplicated_names.mean():.2f}ê±´")
    print(f"  - ìµœë‹¤ ë¯¼ì›: {duplicated_names.max()}ê±´ ({duplicated_names.idxmax()})")

