import json
import logging
import requests
import csv
import os
import sys
import re
import uuid
import math
import random
import datetime
import time  # â­ï¸ ì¬ì‹œë„ ëŒ€ê¸°ë¥¼ ìœ„í•´ time ëª¨ë“ˆ ì¶”ê°€
from qdrant_client import models

# â­ï¸ ê¸°ì¡´ ê´€ë¦¬ íŒŒì¼ì—ì„œ ì„¤ì • ë° í´ë˜ìŠ¤ ê°€ì ¸ì˜¤ê¸°
try:
    sys.path.append(os.getcwd())
    from qdrant_db_manage import QdrantManager, QDRANT_URL, QDRANT_API_KEY, UPSTAGE_API_KEY
except ImportError:
    print("âŒ 'qdrant_db_manage.py' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    sys.exit(1)

# --- [ì„¤ì •] ---
COMPLAINT_FILE = 'data/complaint/complaint_dalseo.json'
ANSWER_FILE = 'data/answer/answer_dalseo.json'
N8N_WEBHOOK_URL = "http://localhost:5678/webhook/48353ac2-642f-46a8-aeba-8deca16202c2"  # â­ï¸ n8n Production URL ì…ë ¥ í•„ìˆ˜

TEST_COL_COMPLAINT = "test_complaint" 
TEST_COL_ANSWER = "test_answer"

RESULT_CSV = "result_random_sampling.csv"     # ê²°ê³¼ ìš”ì•½ íŒŒì¼
IDS_CSV = "selected_ids.csv"                  # ì„ íƒëœ ID ì €ì¥ íŒŒì¼
REQUEST_LOG_TXT = "requests_log.txt"          # Request ê¸°ë¡ íŒŒì¼
RESPONSE_LOG_FILE = "n8n_detailed_log.txt"    # [ì¶”ê°€] Response ìƒì„¸ ë¡œê·¸

MAX_CONTENT_LENGTH = 3000
BATCH_SIZE = 50 

# ìƒ˜í”Œë§ ê°œìˆ˜ ì„¤ì •
TRAIN_SAMPLE_SIZE = 1000
TEST_SAMPLE_SIZE = 100

# --- ë¡œê¹… ì„¤ì • ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
log = logging.getLogger()

def extract_final_dept(dept_str):
    if not isinstance(dept_str, str) or not dept_str: return ""
    clean_str = re.sub(r'[:/>,]', ' ', dept_str)
    parts = clean_str.split()
    if parts: return parts[-1].strip()
    return ""

def save_response_log(item_id, res_json, is_success=True):
    """n8n ì‘ë‹µ ë¡œê·¸ ì €ì¥"""
    try:
        with open(RESPONSE_LOG_FILE, 'a', encoding='utf-8') as f:
            timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            status = "âœ… SUCCESS" if is_success else "âŒ FAILED"
            json_str = json.dumps(res_json, indent=2, ensure_ascii=False) if res_json else "No Data"
            
            log_entry = (
                f"[{timestamp}] [ID: {item_id}] {status}\n"
                f"{json_str}\n"
                f"{'-'*80}\n"
            )
            f.write(log_entry)
    except Exception: pass

def call_n8n_workflow(complaint_input, max_retries=3):
    """
    n8n Webhook í˜¸ì¶œ (ì¬ì‹œë„ ë¡œì§ ë° ê¸´ íƒ€ì„ì•„ì›ƒ ì ìš©)
    """
    if not N8N_WEBHOOK_URL: return None
    
    for attempt in range(max_retries):
        try:
            # â­ï¸ íƒ€ì„ì•„ì›ƒì„ 300ì´ˆ(5ë¶„)ë¡œ ì„¤ì •í•˜ì—¬ ì¶©ë¶„íˆ ê¸°ë‹¤ë¦¼
            response = requests.post(N8N_WEBHOOK_URL, json=complaint_input, timeout=300)
            
            if response.status_code == 200:
                res_json = response.json()
                
                # ë¡œê·¸ ì €ì¥
                save_response_log(complaint_input.get('id'), res_json, is_success=True)

                # íŒŒì‹± ë¡œì§
                target = res_json[0] if isinstance(res_json, list) and res_json else res_json
                if isinstance(target, dict):
                    if 'recommended_dept' in target: return target['recommended_dept']
                    if 'json' in target and 'recommended_dept' in target['json']: return target['json']['recommended_dept']
                    if 'metadata' in target and 'recommended_dept' in target['metadata']: return target['metadata']['recommended_dept']
                return None # ì‘ë‹µì€ ì™”ìœ¼ë‚˜ êµ¬ì¡°ê°€ ë‹¤ë¦„
            
            else:
                log.warning(f"   âš ï¸ [ID: {complaint_input.get('id')}] ì„œë²„ ì˜¤ë¥˜ ({response.status_code}). ì¬ì‹œë„ ì¤‘... ({attempt+1}/{max_retries})")
        
        except requests.exceptions.Timeout:
            log.warning(f"   â³ [ID: {complaint_input.get('id')}] íƒ€ì„ì•„ì›ƒ ë°œìƒ. ì¬ì‹œë„ ì¤‘... ({attempt+1}/{max_retries})")
        except Exception as e:
            log.warning(f"   âš ï¸ [ID: {complaint_input.get('id')}] í†µì‹  ì—ëŸ¬: {e}. ì¬ì‹œë„ ì¤‘... ({attempt+1}/{max_retries})")
        
        # ì¬ì‹œë„ ì „ ì ì‹œ ëŒ€ê¸°
        time.sleep(2)

    # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ ì‹œ
    log.error(f"   âŒ [ID: {complaint_input.get('id')}] ìµœì¢… ì‹¤íŒ¨ (ì‘ë‹µ ì—†ìŒ)")
    save_response_log(complaint_input.get('id'), None, is_success=False)
    return None

def save_selected_ids(train_items, test_items, filename):
    try:
        train_ids = sorted([int(item['id']) for item in train_items if 'id' in item])
        test_ids = sorted([int(item['id']) for item in test_items if 'id' in item])
        
        with open(filename, 'w', encoding='utf-8', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['type', 'count', 'ids'])
            writer.writerow(['TRAIN', len(train_ids), ",".join(map(str, train_ids))])
            writer.writerow(['TEST', len(test_ids), ",".join(map(str, test_ids))])
            
        log.info(f"ğŸ’¾ ì„ íƒëœ ID ëª©ë¡ ì €ì¥ ì™„ë£Œ: '{filename}'")
    except Exception as e:
        log.error(f"âŒ ID ì €ì¥ ì‹¤íŒ¨: {e}")

def save_request_log(item):
    try:
        with open(REQUEST_LOG_TXT, 'a', encoding='utf-8') as f:
            timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            content_preview = item.get('content', '').replace('\n', ' ')[:100]
            log_line = (
                f"[{timestamp}] "
                f"ID: {item.get('id')} | "
                f"Title: {item.get('title')} | "
                f"Content: {content_preview}...\n"
            )
            f.write(log_line)
    except Exception: pass

def upload_to_qdrant_separate(manager, complaints, answers):
    # 1. ë¯¼ì› ì—…ë¡œë“œ
    total_c = len(complaints)
    log.info(f"   ğŸ”„ [ë¯¼ì›] {total_c}ê°œ ì—…ë¡œë“œ ì¤‘... ({TEST_COL_COMPLAINT})")
    try:
        manager.client.recreate_collection(
            collection_name=TEST_COL_COMPLAINT,
            vectors_config=models.VectorParams(size=manager.vector_size, distance=models.Distance.COSINE)
        )
    except Exception as e: log.error(f"   âŒ ë¯¼ì› ì»¬ë ‰ì…˜ ì—ëŸ¬: {e}"); return

    points = []
    one_percent_c = max(1, math.floor(total_c / 100))

    for i, item in enumerate(complaints):
        text = f"{item['title']}\n\n{item['content']}"
        if len(text) > MAX_CONTENT_LENGTH: text = text[:MAX_CONTENT_LENGTH]
        try:
            vector = manager.generate_embedding(text)
            payload = {
                "content": text,
                "metadata": {
                    "id": str(item['id']),
                    "title": item['title'],
                    "author": item['author'],
                    "dept": item.get('dept', ''),
                    "created_date": item['created_date']
                }
            }
            points.append(models.PointStruct(id=str(uuid.uuid4()), vector=vector, payload=payload))
        except: continue
        
        if len(points) >= BATCH_SIZE:
            manager.client.upsert(collection_name=TEST_COL_COMPLAINT, points=points)
            points = []
        
        if (i + 1) % one_percent_c == 0:
             print(f"      [ë¯¼ì› ì—…ë¡œë“œ] {int((i + 1) / total_c * 100)}% ì™„ë£Œ ({i + 1}/{total_c})")
        
    if points: manager.client.upsert(collection_name=TEST_COL_COMPLAINT, points=points)

    # 2. ë‹µë³€ ì—…ë¡œë“œ
    total_a = len(answers)
    log.info(f"   ğŸ”„ [ë‹µë³€] {total_a}ê°œ ì—…ë¡œë“œ ì¤‘... ({TEST_COL_ANSWER})")
    try:
        manager.client.recreate_collection(
            collection_name=TEST_COL_ANSWER,
            vectors_config=models.VectorParams(size=manager.vector_size, distance=models.Distance.COSINE)
        )
    except Exception as e: log.error(f"   âŒ ë‹µë³€ ì»¬ë ‰ì…˜ ì—ëŸ¬: {e}"); return

    ans_points = []
    one_percent_a = max(1, math.floor(total_a / 100))

    for i, item in enumerate(answers):
        text = item['content']
        if len(text) > MAX_CONTENT_LENGTH: text = text[:MAX_CONTENT_LENGTH]
        try:
            vector = manager.generate_embedding(text)
            payload = {
                "content": text,
                "metadata": {
                    "id": str(item['id']),
                    "dept": item['dept'],
                    "date": item['date']
                }
            }
            ans_points.append(models.PointStruct(id=str(uuid.uuid4()), vector=vector, payload=payload))
        except: continue

        if len(ans_points) >= BATCH_SIZE:
            manager.client.upsert(collection_name=TEST_COL_ANSWER, points=ans_points)
            ans_points = []
            
        if (i + 1) % one_percent_a == 0:
             print(f"      [ë‹µë³€ ì—…ë¡œë“œ] {int((i + 1) / total_a * 100)}% ì™„ë£Œ ({i + 1}/{total_a})")

    if ans_points: manager.client.upsert(collection_name=TEST_COL_ANSWER, points=ans_points)
    log.info("   âœ… DB ì—…ë¡œë“œ ì™„ë£Œ")

def main():
    log.info(f"--- ğŸš€ ëœë¤ ìƒ˜í”Œë§ í…ŒìŠ¤íŠ¸ (íƒ€ì„ì•„ì›ƒ ë°©ì§€ + ì¬ì‹œë„) ---")
    
    if not N8N_WEBHOOK_URL:
        log.error("âŒ N8N_WEBHOOK_URLì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        return

    # 1. ë°ì´í„° ë¡œë“œ
    with open(COMPLAINT_FILE, 'r', encoding='utf-8') as f: all_complaints = json.load(f)
    with open(ANSWER_FILE, 'r', encoding='utf-8') as f: all_answers = json.load(f)
    ans_dict = {int(a['id']): a for a in all_answers if 'id' in a}
    
    valid_indices = [i for i, item in enumerate(all_complaints) if item.get('content') and item.get('dept')]
    total_valid = len(valid_indices)
    
    log.info(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: ìœ íš¨ ë°ì´í„° {total_valid}ê°œ")
    
    if total_valid < TRAIN_SAMPLE_SIZE + TEST_SAMPLE_SIZE:
        log.error(f"âŒ ë°ì´í„° ë¶€ì¡±: ìµœì†Œ {TRAIN_SAMPLE_SIZE + TEST_SAMPLE_SIZE}ê°œ í•„ìš”")
        return

    # 2. ëœë¤ ìƒ˜í”Œë§
    train_indices = random.sample(valid_indices, TRAIN_SAMPLE_SIZE)
    remaining_indices = list(set(valid_indices) - set(train_indices))
    test_indices = random.sample(remaining_indices, TEST_SAMPLE_SIZE)
    
    train_complaints = [all_complaints[i] for i in train_indices]
    test_items = [all_complaints[i] for i in test_indices]
    
    train_ids = set(int(c['id']) for c in train_complaints)
    train_answers = [ans_dict[i] for i in train_ids if i in ans_dict]
    
    log.info(f"ğŸ² ìƒ˜í”Œë§ ì™„ë£Œ (í•™ìŠµ: {len(train_complaints)}, í…ŒìŠ¤íŠ¸: {len(test_items)})")

    # ì„ íƒëœ ID ì €ì¥
    save_selected_ids(train_complaints, test_items, IDS_CSV)
    
    # ë¡œê·¸ íŒŒì¼ ì´ˆê¸°í™”
    for log_file in [REQUEST_LOG_TXT, RESPONSE_LOG_FILE]:
        with open(log_file, 'w', encoding='utf-8') as f:
            f.write(f"--- Log Started ---\n")

    # CSV í—¤ë”
    try:
        with open(RESULT_CSV, 'w', encoding='utf-8', newline='') as f:
            csv.writer(f).writerow(['trial_id', 'train_count', 'test_count', 'accuracy', 'accuracy_fraction', 'timeout'])
    except: pass

    manager = QdrantManager(QDRANT_URL, QDRANT_API_KEY, UPSTAGE_API_KEY, "dummy")

    # 3. DB ì—…ë¡œë“œ
    upload_to_qdrant_separate(manager, train_complaints, train_answers)

    # 4. í…ŒìŠ¤íŠ¸ ì§„í–‰
    log.info("\n   ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹œì‘ (n8n í˜¸ì¶œ)...")
    correct_cnt = 0
    valid_cnt = 0
    timeout_cnt = 0
    
    total_test = len(test_items)
    one_percent_step = max(1, math.floor(total_test / 100))
    
    for idx, item in enumerate(test_items):
        wf_input = {
            "id": str(item.get('id')),
            "title": item.get('title'),
            "content": item.get('content'),
            "author": item.get('author'),
            "created_date": item.get('created_date'),
            "category": item.get('category')
        }
        
        # Request ë¡œê·¸ ì €ì¥
        save_request_log(item)
        
        # n8n í˜¸ì¶œ (ì¬ì‹œë„ í¬í•¨)
        ai_recommendations = call_n8n_workflow(wf_input)
        
        if ai_recommendations is None:
            timeout_cnt += 1; continue
        
        valid_cnt += 1
        raw_dept = item.get('dept', '').strip()
        target_dept = extract_final_dept(raw_dept)
        
        is_correct = False
        if ai_recommendations:
            if isinstance(ai_recommendations, str): ai_recommendations = [ai_recommendations]
            if isinstance(ai_recommendations, list):
                for rec in ai_recommendations:
                    rec_core = extract_final_dept(str(rec))
                    if rec_core and target_dept:
                        if rec_core == target_dept or rec_core in target_dept or target_dept in rec_core:
                            is_correct = True; break
        
        if is_correct: correct_cnt += 1
        
        if (idx + 1) % one_percent_step == 0:
            progress = (idx + 1) / total_test * 100
            curr_acc = (correct_cnt / valid_cnt * 100) if valid_cnt > 0 else 0
            print(f"      [Testing] {int(progress)}% ì™„ë£Œ ({idx + 1}/{total_test}) - í˜„ì¬ ì •í™•ë„: {curr_acc:.1f}%")

    acc = round(correct_cnt / valid_cnt, 4) if valid_cnt > 0 else 0.0
    fraction = f"{correct_cnt}/{valid_cnt}"
    
    # ê²°ê³¼ ì €ì¥
    with open(RESULT_CSV, 'a', encoding='utf-8', newline='') as f:
        csv.writer(f).writerow([1, len(train_complaints), len(test_items), acc, fraction, timeout_cnt])
        
    log.info(f"\nğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: ì •í™•ë„ {acc*100:.2f}% ({fraction}) / íƒ€ì„ì•„ì›ƒ {timeout_cnt}")
    log.info(f"ğŸ ê²°ê³¼ íŒŒì¼: '{RESULT_CSV}', '{IDS_CSV}', '{RESPONSE_LOG_FILE}'")

if __name__ == "__main__":
    main()